{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age        date     category   price\n",
      "0   25  2023-01-01  Electronics     100\n",
      "1   30  01/15/2023  electronics   208.5\n",
      "2    5     invalid     Clothing     N/A\n",
      "3  150  2023-02-28         FOOD     300\n",
      "4   40  03-15-2023         food  150.75\n",
      "----\n",
      "   age       date     category   price\n",
      "0   25 2023-01-01  electronics  100.00\n",
      "1   30        NaT  electronics  208.50\n",
      "2    5        NaT     clothing     NaN\n",
      "3  120 2023-02-28         food  300.00\n",
      "4   40        NaT         food  150.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_data(df):\n",
    "    #Remove duplicates\n",
    "    df=df.drop_duplicates()\n",
    "\n",
    "    #handle outliers\n",
    "    df['age']=df['age'].clip(0,120)\n",
    "\n",
    "    #Correct structural errors\n",
    "    df['date']=pd.to_datetime(df['date'],errors='coerce')\n",
    "\n",
    "    # Standardize text data (e.g., for ’category’ column)\n",
    "    df['category']=df['category'].str.lower().str.strip()\n",
    "\n",
    "    #Type conversion\n",
    "    df['price']=pd.to_numeric(df['price'],errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "#Example Usage\n",
    "\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'age': [25, 30, 5, 150, 40],\n",
    "    'date': ['2023-01-01', '01/15/2023', 'invalid', '2023-02-28', '03-15-2023'],\n",
    "    'category': ['Electronics', 'electronics', 'Clothing', 'FOOD', 'food'],\n",
    "    'price': ['100', '208.5', 'N/A', '300', '150.75']\n",
    "})\n",
    "\n",
    "print(data)\n",
    "print('----')\n",
    "cleaned_data=clean_data(data)\n",
    "print(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C\n",
      "0  1.0  3.3  1.0\n",
      "1  2.0  2.0  2.0\n",
      "2  3.0  3.0  3.0\n",
      "3  4.0  3.3  4.0\n",
      "4  5.0  5.0  2.5\n"
     ]
    }
   ],
   "source": [
    "def handle_missing_data(df):\n",
    "    # Identify columns with missing data\n",
    "    columns_with_missing = df.columns[df.isnull().any()].tolist()\n",
    "\n",
    "    for column in columns_with_missing:\n",
    "        missing_percentage = df[column].isnull().sum() / len(df) * 100\n",
    "\n",
    "        if missing_percentage < 5:\n",
    "            # For Low percentage of missing data, use mean imputation\n",
    "            df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "        elif missing_percentage < 15:\n",
    "            # For moderate missing data, use median imputation\n",
    "            df[column].fillna(df[column].median(), inplace=True)\n",
    "\n",
    "        else:\n",
    "            # For high percentage of missing data, use KNN imputation\n",
    "            # Round off to 1 integers for more consistency\n",
    "            imputer = KNNImputer(n_neighbors=5)\n",
    "            df[column] = np.round(imputer.fit_transform(df[[column]]),1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, 2, 3, 4, np.nan]\n",
    "})\n",
    "\n",
    "cleaned_data = handle_missing_data(data)\n",
    "print(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data normalization and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   A  B  C\n",
      "  1 10 -1\n",
      "  2 20 -2\n",
      "  3 30  0\n",
      "  4 40  2\n",
      "100 50  1\n",
      "\n",
      "Min-Max Scaled:\n",
      "        A    B    C\n",
      "0.000000 0.00 0.25\n",
      "0.010101 0.25 0.00\n",
      "0.020202 0.50 0.50\n",
      "0.030303 0.75 1.00\n",
      "1.000000 1.00 0.75\n",
      "\n",
      "Standardized:\n",
      "         A         B         C\n",
      "-0.538285 -1.414214 -0.707107\n",
      "-0.512652 -0.707107 -1.414214\n",
      "-0.487019  0.000000  0.000000\n",
      "-0.461387  0.707107  1.414214\n",
      " 1.999343  1.414214  0.707107\n",
      "\n",
      "Robust Scaled: \n",
      "    A    B    C\n",
      "-1.0 -1.0 -0.5\n",
      "-0.5 -0.5 -1.0\n",
      " 0.0  0.0  0.0\n",
      " 0.5  0.5  1.0\n",
      "48.5  1.0  0.5\n"
     ]
    }
   ],
   "source": [
    "def normalize_and_standardize(df):\n",
    "    # Create copies of the dataframe for different scaling methods\n",
    "    df_minmax = df.copy()\n",
    "    df_standard = df.copy()\n",
    "    df_robust = df.copy()\n",
    "\n",
    "    # Initialize scalers\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    standard_scaler = StandardScaler()\n",
    "    robust_scaler = RobustScaler()\n",
    "\n",
    "    # Apply scaling to numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    df_minmax[numeric_columns] = minmax_scaler.fit_transform(df[numeric_columns])\n",
    "    df_standard[numeric_columns] = standard_scaler.fit_transform(df[numeric_columns])\n",
    "    df_robust[numeric_columns] = robust_scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "    return df_minmax, df_standard, df_robust\n",
    "\n",
    "# Example usage\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 100],\n",
    "    'B': [10, 20, 30, 40, 50],\n",
    "    'C': [-1, -2, 0, 2, 1]\n",
    "})\n",
    "\n",
    "minmax_scaled, standard_scaled, robust_scaled = normalize_and_standardize(data)\n",
    "\n",
    "print(\"Original Data:\\n\", data.to_string(index=False))\n",
    "print(\"\\nMin-Max Scaled:\\n\", minmax_scaled.to_string(index=False))\n",
    "print(\"\\nStandardized:\\n\", standard_scaled.to_string(index=False))\n",
    "print(\"\\nRobust Scaled: \\n\", robust_scaled.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data quality metrics and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completeness:\n",
      "  id: 1.00\n",
      "  name: 0.80\n",
      "  age: 1.00\n",
      "  date: 1.00\n",
      "\n",
      "Uniqueness:\n",
      "  id: 1.00\n",
      "  name: 0.80\n",
      "  age: 1.00\n",
      "  date: 1.00\n",
      "\n",
      "Validity:\n",
      "  id: 1.00\n",
      "  name: nan\n",
      "  age: 1.00\n",
      "  date: nan\n",
      "\n",
      "Date_range_days:\n",
      "  4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def assess_data_quality(df):\n",
    "    quality_report = {}\n",
    "\n",
    "    # Completeness\n",
    "    quality_report['completeness'] = df.notna().mean().to_dict()\n",
    "\n",
    "    # Uniqueness\n",
    "    quality_report['uniqueness'] = (df.nunique() / len(df)).to_dict()\n",
    "\n",
    "    # Basic validity checks\n",
    "    def check_validity(column):\n",
    "        if pd.api.types.is_numeric_dtype(column):\n",
    "            return (column >= 0).mean()  # Assuming non-negative values are valid\n",
    "        elif pd.api.types.is_string_dtype(column):\n",
    "            return column.str.match(r'^[A-Za-z\\s]+$').mean()  # Assuming only letters and spaces are valid\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    quality_report['validity'] = df.apply(check_validity).to_dict()\n",
    "\n",
    "    # Consistency (example: checking date range)\n",
    "    if 'date' in df.columns:\n",
    "        date_range = df['date'].max() - df['date'].min()\n",
    "        quality_report['date_range_days'] = date_range.days\n",
    "\n",
    "    return quality_report\n",
    "\n",
    "# Example usage\n",
    "data = pd.DataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['John Doe', 'Jane Doe', 'Bob Smith', np.nan, '123'],\n",
    "    'age': [30, 25, 5, 40, 35],\n",
    "    'date': pd.date_range(start='2023-01-01', periods=5)\n",
    "})\n",
    "\n",
    "quality_metrics = assess_data_quality(data)\n",
    "for metric, values in quality_metrics.items():\n",
    "    print(f\"\\n{metric.capitalize()}:\")\n",
    "    if isinstance(values, dict):\n",
    "        for col, val in values.items():\n",
    "            print(f\"  {col}: {val:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {values}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
