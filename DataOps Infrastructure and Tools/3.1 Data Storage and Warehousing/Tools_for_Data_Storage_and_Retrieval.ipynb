{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeq8qdd7Itr_"
      },
      "source": [
        "# Cloud storage solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code mounts Google Drive, saves a pandas DataFrame as a CSV file to Google Drive, and then reads it back into a DataFrame. This contrasts with the textbook's use of Amazon S3 for data storage and retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cf6i0Gtm_VJG",
        "outputId": "dbea4340-1a7a-4828-bcb5-2b302535d9b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Data saved to Google Drive at: /content/drive/My Drive/data/sales_2023.csv\n",
            "Data read from Google Drive:\n",
            "         date  sales\n",
            "0  2023-01-01    100\n",
            "1  2023-01-02    150\n",
            "2  2023-01-03    200\n",
            "3  2023-01-04    120\n",
            "4  2023-01-05    180\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define functions\n",
        "def save_to_drive(df, file_path):\n",
        "    # Create directories if they do not exist\n",
        "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "    csv_buffer = StringIO()\n",
        "    df.to_csv(csv_buffer, index=False)\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(csv_buffer.getvalue())\n",
        "\n",
        "def read_from_drive(file_path):\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/drive/My Drive/data/sales_2023.csv'\n",
        "\n",
        "# Create sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'date': pd.date_range(start='2023-01-01', periods=5),\n",
        "    'sales': [100, 150, 200, 120, 180]\n",
        "})\n",
        "\n",
        "# Save DataFrame to Google Drive\n",
        "save_to_drive(df, file_path)\n",
        "print(f\"Data saved to Google Drive at: {file_path}\")\n",
        "\n",
        "# Read DataFrame from Google Drive\n",
        "df_from_drive = read_from_drive(file_path)\n",
        "print(\"Data read from Google Drive:\")\n",
        "print(df_from_drive)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmMgnD2gJspS"
      },
      "source": [
        "# Distributed file systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code mounts Google Drive, writes a pandas DataFrame to a Parquet file on Google Drive, and then reads it back into a DataFrame. The textbook uses HDFS for similar operations, which involves a more complex setup for big data storage and retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QipXxBuK_VFf",
        "outputId": "97949d3f-3420-481d-de40-b0449ce41598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Data written to Google Drive: /content/drive/My Drive/data/sales_2023.parquet\n",
            "Data read from Google Drive:\n",
            "        date  sales\n",
            "0 2023-01-01    100\n",
            "1 2023-01-02    150\n",
            "2 2023-01-03    200\n",
            "3 2023-01-04    120\n",
            "4 2023-01-05    180\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define functions\n",
        "def write_to_drive(df, path):\n",
        "    table = pa.Table.from_pandas(df)\n",
        "    buffer = BytesIO()\n",
        "    pq.write_table(table, buffer)\n",
        "    with open(path, 'wb') as f:\n",
        "        f.write(buffer.getvalue())\n",
        "\n",
        "def read_from_drive(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        buffer = BytesIO(f.read())\n",
        "    table = pq.read_table(buffer)\n",
        "    return table.to_pandas()\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/drive/My Drive/data/sales_2023.parquet'\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "# Create sample DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'date': pd.date_range(start='2023-01-01', periods=5),\n",
        "    'sales': [100, 150, 200, 120, 180]\n",
        "})\n",
        "\n",
        "# Write DataFrame to Google Drive as Parquet\n",
        "write_to_drive(df, file_path)\n",
        "print(f\"Data written to Google Drive: {file_path}\")\n",
        "\n",
        "# Read DataFrame from Google Drive\n",
        "df_from_drive = read_from_drive(file_path)\n",
        "print(\"Data read from Google Drive:\")\n",
        "print(df_from_drive)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p20-kdsEbS9w"
      },
      "source": [
        "# Database management systems for DataOps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Demonstrates how to use PostgreSQL in a DataOps workflow, including creating tables, inserting data, and performing analytical queries. It showcases the integration of DBMS with data processing libraries like pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vStKvPd6bVXA",
        "outputId": "c9cf6da8-1803-4ff6-e54c-2505eba0358c"
      },
      "outputs": [],
      "source": [
        "!pip install pandas sqlalchemy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iU235cAbVZf",
        "outputId": "62979f98-6239-46fe-affa-14c9d3ee6b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sales summary:\n",
            "                         date  total_sales\n",
            "0  2023-01-01 00:00:00.000000        100.0\n",
            "1  2023-01-02 00:00:00.000000        150.0\n",
            "2  2023-01-03 00:00:00.000000        200.0\n",
            "3  2023-01-04 00:00:00.000000        120.0\n",
            "4  2023-01-05 00:00:00.000000        180.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# Create a SQLite engine that uses an in-memory database\n",
        "engine = create_engine('sqlite:///:memory:')\n",
        "\n",
        "# Connect to the engine and create a table\n",
        "with engine.connect() as conn:\n",
        "    # Execute SQL command to create a table using the `text()` function to ensure the SQL command is executable\n",
        "    conn.execute(text(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS sales (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        date DATE,\n",
        "        amount FLOAT\n",
        "    )\n",
        "    \"\"\"))\n",
        "\n",
        "    # Prepare data for insertion\n",
        "    df = pd.DataFrame({\n",
        "        'date': pd.date_range('2023-01-01', periods=5),\n",
        "        'amount': [100, 150, 200, 120, 180]\n",
        "    })\n",
        "\n",
        "    # Insert data using pandas DataFrame.to_sql method\n",
        "    df.to_sql('sales', con=engine, if_exists='append', index=False)  # Note the change from conn to engine for `to_sql`\n",
        "\n",
        "    # Prepare SQL query to sum amounts by date\n",
        "    query = text(\"\"\"\n",
        "    SELECT date, SUM(amount) as total_sales FROM sales GROUP BY date ORDER BY date\n",
        "    \"\"\")\n",
        "\n",
        "    # Execute query and store results in a DataFrame\n",
        "    result_df = pd.read_sql_query(query, con=engine)  # Using engine for consistency in `read_sql_query`\n",
        "\n",
        "    # Print summary results\n",
        "    print(\"Sales summary:\")\n",
        "    print(result_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
